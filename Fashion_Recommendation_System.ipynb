{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1u0raR3d3TtKy2cdXG6KpCjRBe_payhJ3",
      "authorship_tag": "ABX9TyPUEe53VZloq9qUuiIOhlwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tndeal/Fashion-recommendation-system/blob/main/Fashion_Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTpxwzwcBwBX",
        "outputId": "777b0435-76a2-46d1-b97c-60bbd398142c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
          ]
        }
      ],
      "source": [
        "## imports\n",
        "from bs4 import *\n",
        "import requests\n",
        "import os\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "import numpy as np\n",
        "import os\n",
        "!pip install google-search-results\n",
        "!pip install googledriver\n",
        "!pip install pyyaml h5py\n",
        "from serpapi import GoogleSearch\n",
        "vgg16 = keras.applications.vgg16\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#sets up tensorflow configuration\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
        "\n",
        "#sort data\n",
        "!unzip /content/drive/MyDrive/Adatamanipulation/img.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracts all possible category names from the list of images\n",
        "def sortdata(data_file):\n",
        "  category_list = []\n",
        "  text_file = open(data_file)\n",
        "  lines = text_file.readlines()\n",
        "  for i in range (2, len(lines)):\n",
        "    split = lines[i].split('/')\n",
        "    title = split[1]\n",
        "    if len(title.split('_')) >= 3:\n",
        "        title = title[0]+'_'+title[-1]\n",
        "    if title not in category_list:\n",
        "      category_list.append(title)\n",
        "  print(len(category_list))\n",
        "  return category_list\n",
        "category_list = sortdata('/content/drive/MyDrive/Adatamanipulation/list_category_img.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2siNp2-WN8kB",
        "outputId": "8cfc168c-6641-47d4-fd93-c04056fddbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MODEL\n",
        "\n",
        "\n",
        "\n",
        "#sets up training and validation datasets\n",
        "def setup_datasets(dataset_location):\n",
        "  imagedatagenerator = keras.preprocessing.image.ImageDataGenerator(\n",
        "      preprocessing_function = vgg16.preprocess_input,\n",
        "      horizontal_flip = True,\n",
        "      validation_split = 0.1)\n",
        "\n",
        "  train_dataset = imagedatagenerator.flow_from_directory(\n",
        "      directory = dataset_location,\n",
        "      target_size = (100, 100),\n",
        "      classes = category_list,\n",
        "      batch_size = 32,\n",
        "      subset = 'training')\n",
        "\n",
        "  val_dataset = imagedatagenerator.flow_from_directory(\n",
        "      directory = dataset_location,\n",
        "      target_size = (100, 100),\n",
        "      classes = category_list,\n",
        "      batch_size = 32,\n",
        "      subset = 'validation')\n",
        "\n",
        "  return train_dataset, val_dataset\n",
        "\n",
        "#changes vgg16 model to specific parameters\n",
        "def alter_model(vgg_model):\n",
        "  x = keras.layers.Flatten()(vgg_model.output)\n",
        "  x = keras.layers.Dense(100, activation='relu')(x)\n",
        "  x = keras.layers.Dense(50, activation='relu')(x)\n",
        "  predictions = keras.layers.Dense(383, activation='softmax')(x)\n",
        "  full_model = keras.models.Model(inputs=vgg_model.input, outputs=predictions)\n",
        "  full_model.summary()\n",
        "  return full_model\n",
        "\n",
        "\n",
        "#create training and valdidation datasets\n",
        "train_dataset, val_dataset = setup_datasets('/content/img')\n",
        "X_train, y_train = next(train_dataset)\n",
        "\n",
        "\n",
        "#setup initial vgg16 model\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(100,100,3))\n",
        "vgg_model.trainable = False\n",
        "vgg_model.summary()\n",
        "\n",
        "#alter vgg16 model\n",
        "full_model = alter_model(vgg_model)\n",
        "full_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['acc'])\n",
        "\n",
        "#train model\n",
        "history = full_model.fit(train_dataset, validation_data = val_dataset, workers=0, epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ogzhV7vaB7je",
        "outputId": "3ae8e05b-54d5-4f08-f731-ac4733f3e709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383\n",
            "Found 11079 images belonging to 383 classes.\n",
            "Found 1130 images belonging to 383 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               460900    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 383)               19533     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15200171 (57.98 MB)\n",
            "Trainable params: 485483 (1.85 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "347/347 [==============================] - 28s 59ms/step - loss: 5.3083 - acc: 0.0390 - val_loss: 4.4563 - val_acc: 0.0850\n",
            "Epoch 2/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 4.2299 - acc: 0.1052 - val_loss: 3.9805 - val_acc: 0.1212\n",
            "Epoch 3/50\n",
            "347/347 [==============================] - 16s 47ms/step - loss: 3.7708 - acc: 0.1505 - val_loss: 3.8116 - val_acc: 0.1513\n",
            "Epoch 4/50\n",
            "347/347 [==============================] - 17s 49ms/step - loss: 3.4629 - acc: 0.1945 - val_loss: 3.7743 - val_acc: 0.1681\n",
            "Epoch 5/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 3.2166 - acc: 0.2299 - val_loss: 3.7698 - val_acc: 0.1681\n",
            "Epoch 6/50\n",
            "347/347 [==============================] - 17s 48ms/step - loss: 3.0158 - acc: 0.2638 - val_loss: 3.8853 - val_acc: 0.1637\n",
            "Epoch 7/50\n",
            "347/347 [==============================] - 16s 45ms/step - loss: 2.8335 - acc: 0.2944 - val_loss: 3.9449 - val_acc: 0.1726\n",
            "Epoch 8/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 2.6863 - acc: 0.3245 - val_loss: 4.0623 - val_acc: 0.1903\n",
            "Epoch 9/50\n",
            "347/347 [==============================] - 16s 47ms/step - loss: 2.5474 - acc: 0.3484 - val_loss: 4.2296 - val_acc: 0.1690\n",
            "Epoch 10/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 2.4149 - acc: 0.3776 - val_loss: 4.2155 - val_acc: 0.1841\n",
            "Epoch 11/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 2.3013 - acc: 0.4026 - val_loss: 4.4899 - val_acc: 0.1779\n",
            "Epoch 12/50\n",
            "347/347 [==============================] - 16s 45ms/step - loss: 2.2163 - acc: 0.4158 - val_loss: 4.5555 - val_acc: 0.1788\n",
            "Epoch 13/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 2.0947 - acc: 0.4475 - val_loss: 4.7143 - val_acc: 0.1717\n",
            "Epoch 14/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 1.9951 - acc: 0.4678 - val_loss: 4.9000 - val_acc: 0.1850\n",
            "Epoch 15/50\n",
            "347/347 [==============================] - 17s 47ms/step - loss: 1.9145 - acc: 0.4860 - val_loss: 5.1317 - val_acc: 0.1796\n",
            "Epoch 16/50\n",
            "347/347 [==============================] - 16s 45ms/step - loss: 1.8565 - acc: 0.5036 - val_loss: 5.1660 - val_acc: 0.1752\n",
            "Epoch 17/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 1.7703 - acc: 0.5224 - val_loss: 5.3720 - val_acc: 0.1841\n",
            "Epoch 18/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 1.7104 - acc: 0.5392 - val_loss: 5.4778 - val_acc: 0.1699\n",
            "Epoch 19/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 1.6668 - acc: 0.5475 - val_loss: 5.6890 - val_acc: 0.1628\n",
            "Epoch 20/50\n",
            "347/347 [==============================] - 17s 48ms/step - loss: 1.5997 - acc: 0.5630 - val_loss: 6.1259 - val_acc: 0.1708\n",
            "Epoch 21/50\n",
            "347/347 [==============================] - 18s 52ms/step - loss: 1.5603 - acc: 0.5706 - val_loss: 5.9212 - val_acc: 0.1708\n",
            "Epoch 22/50\n",
            "347/347 [==============================] - 17s 50ms/step - loss: 1.4932 - acc: 0.5900 - val_loss: 6.2236 - val_acc: 0.1628\n",
            "Epoch 23/50\n",
            "347/347 [==============================] - 16s 47ms/step - loss: 1.4720 - acc: 0.5914 - val_loss: 6.7045 - val_acc: 0.1673\n",
            "Epoch 24/50\n",
            "347/347 [==============================] - 17s 48ms/step - loss: 1.4119 - acc: 0.6069 - val_loss: 6.6298 - val_acc: 0.1770\n",
            "Epoch 25/50\n",
            "347/347 [==============================] - 17s 48ms/step - loss: 1.3566 - acc: 0.6171 - val_loss: 6.8708 - val_acc: 0.1788\n",
            "Epoch 26/50\n",
            "347/347 [==============================] - 17s 48ms/step - loss: 1.3160 - acc: 0.6372 - val_loss: 6.7869 - val_acc: 0.1708\n",
            "Epoch 27/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 1.2707 - acc: 0.6450 - val_loss: 7.2564 - val_acc: 0.1876\n",
            "Epoch 28/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 1.2328 - acc: 0.6492 - val_loss: 7.2346 - val_acc: 0.1841\n",
            "Epoch 29/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 1.2025 - acc: 0.6577 - val_loss: 7.5683 - val_acc: 0.1575\n",
            "Epoch 30/50\n",
            "347/347 [==============================] - 16s 45ms/step - loss: 1.2191 - acc: 0.6560 - val_loss: 7.6763 - val_acc: 0.1699\n",
            "Epoch 31/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 1.1942 - acc: 0.6613 - val_loss: 8.0534 - val_acc: 0.1699\n",
            "Epoch 32/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 1.1695 - acc: 0.6674 - val_loss: 8.1341 - val_acc: 0.1602\n",
            "Epoch 33/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 1.1340 - acc: 0.6763 - val_loss: 8.1438 - val_acc: 0.1584\n",
            "Epoch 34/50\n",
            "347/347 [==============================] - 17s 48ms/step - loss: 1.0875 - acc: 0.6872 - val_loss: 8.3703 - val_acc: 0.1619\n",
            "Epoch 35/50\n",
            "347/347 [==============================] - 17s 47ms/step - loss: 1.0459 - acc: 0.6993 - val_loss: 8.6767 - val_acc: 0.1593\n",
            "Epoch 36/50\n",
            "347/347 [==============================] - 17s 48ms/step - loss: 1.0126 - acc: 0.7094 - val_loss: 8.6552 - val_acc: 0.1619\n",
            "Epoch 37/50\n",
            "347/347 [==============================] - 20s 57ms/step - loss: 1.0076 - acc: 0.7123 - val_loss: 8.8150 - val_acc: 0.1451\n",
            "Epoch 38/50\n",
            "347/347 [==============================] - 16s 47ms/step - loss: 1.0286 - acc: 0.7044 - val_loss: 8.8857 - val_acc: 0.1664\n",
            "Epoch 39/50\n",
            "347/347 [==============================] - 16s 47ms/step - loss: 0.9778 - acc: 0.7162 - val_loss: 9.4041 - val_acc: 0.1584\n",
            "Epoch 40/50\n",
            "347/347 [==============================] - 16s 47ms/step - loss: 0.9526 - acc: 0.7261 - val_loss: 9.3790 - val_acc: 0.1611\n",
            "Epoch 41/50\n",
            "347/347 [==============================] - 16s 47ms/step - loss: 0.9594 - acc: 0.7193 - val_loss: 9.5703 - val_acc: 0.1504\n",
            "Epoch 42/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 0.9439 - acc: 0.7349 - val_loss: 10.2528 - val_acc: 0.1690\n",
            "Epoch 43/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 0.8667 - acc: 0.7514 - val_loss: 10.3721 - val_acc: 0.1708\n",
            "Epoch 44/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 0.8982 - acc: 0.7404 - val_loss: 10.4602 - val_acc: 0.1637\n",
            "Epoch 45/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 0.8832 - acc: 0.7433 - val_loss: 10.5961 - val_acc: 0.1478\n",
            "Epoch 46/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 0.8910 - acc: 0.7452 - val_loss: 10.9836 - val_acc: 0.1708\n",
            "Epoch 47/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 0.8650 - acc: 0.7520 - val_loss: 10.9909 - val_acc: 0.1566\n",
            "Epoch 48/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 0.8218 - acc: 0.7629 - val_loss: 11.2384 - val_acc: 0.1442\n",
            "Epoch 49/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 0.8146 - acc: 0.7663 - val_loss: 11.6098 - val_acc: 0.1487\n",
            "Epoch 50/50\n",
            "347/347 [==============================] - 16s 46ms/step - loss: 0.8096 - acc: 0.7656 - val_loss: 11.4243 - val_acc: 0.1363\n"
          ]
        }
        
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_model.save('/content/drive/MyDrive/my_model.h5')"
      ],
      "metadata": {
        "id": "DWYPZH04LMWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## INPUTS\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/my_model.h5')\n",
        "\n",
        "## RUN MODEL ON INPUTS\n",
        "\n",
        "#prepares the images for the model and runs the model to predict categories\n",
        "def run_model(path):\n",
        "  img = tf.keras.preprocessing.image.load_img(path, target_size=(100,100))\n",
        "  subject = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  subject = preprocess_input(subject)\n",
        "  subject = np.expand_dims(subject, axis = 0)\n",
        "  features = model.predict(subject)\n",
        "  features = np.argmax(features, axis=1)\n",
        "  features = int(features)\n",
        "  name = category_list[features]\n",
        "  return name, img\n",
        "\n",
        "#returns list of categories of the images\n",
        "def return_model_run():\n",
        "\n",
        "  allimages = []\n",
        "  for i in os.listdir(userfilepath):\n",
        "    name, image = run_model(os.path.join(userfilepath, i))\n",
        "    allimages.append(name)\n",
        "  return allimages\n",
        "\n",
        "\n",
        "#sorts list of categories by most common\n",
        "def find_frequencies(category_list):\n",
        "  frequency = {}\n",
        "\n",
        "  for name in category_list:\n",
        "    if name in frequency:\n",
        "      frequency[name] += 1\n",
        "    else:\n",
        "      frequency[name] = 1\n",
        "\n",
        "  frequency_list = []\n",
        "  for key, value in frequency.items():\n",
        "    frequency_list.append([key, value])\n",
        "\n",
        "\n",
        "  return frequency_list\n",
        "\n",
        "def merge(left, right):\n",
        "    i = 0\n",
        "    j = 0\n",
        "    sortedlist = []\n",
        "    while i < len(left) and j < len(right):\n",
        "        if left[i][1] > right[j][1]:\n",
        "            sortedlist.append(left[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            sortedlist.append(right[j])\n",
        "            j += 1\n",
        "\n",
        "    while j < len(right):\n",
        "        sortedlist.append(right[j])\n",
        "        j += 1\n",
        "    while i< len(left):\n",
        "        sortedlist.append(left[i])\n",
        "        i += 1\n",
        "    return sortedlist\n",
        "\n",
        "def mergesort(givenlist):\n",
        "    if len(givenlist) != 1:\n",
        "        midpoint = len(givenlist) // 2\n",
        "        left = givenlist[:midpoint]\n",
        "        right = givenlist[midpoint:]\n",
        "        left = mergesort(left)\n",
        "        right = mergesort(right)\n",
        "        return merge(left, right)\n",
        "    else:\n",
        "      return givenlist\n",
        "\n",
        "#TAKING INPUTS\n",
        "\n",
        "\"\"\"user_file = input('please enter folder name containing images')\n",
        "userfilepath = os.path.join('/content', user_file)\n",
        "exists = os.path.exists(userfilepath)\n",
        "while exists == False:\n",
        "  check = input('folder does not exist, please enter a different folder name')\n",
        "  if (os.path.exists(check)) == False:\n",
        "    exists = False\n",
        "  else:\n",
        "    exists = True\n",
        "\"\"\"\n",
        "\n",
        "#SHARING A GOOGLE DRIVE LINK\n",
        "url = input(\"please enter google drive link\")\n",
        "  #url validation\n",
        "while 'https://drive.google.com/' not in url:\n",
        "  url = input(\"please enter google drive link\")\n",
        "print(\"link accepted\")\n",
        "\n",
        "  #user file validation\n",
        "user_file = input('please enter file name to be stored under')\n",
        "userfilepath = os.path.join('/content', user_file)\n",
        "exists = os.path.exists(userfilepath)\n",
        "valid = False\n",
        "while exists == True:\n",
        "  check = input('file already exists, use this folder? Y/N')\n",
        "  if check == 'N':\n",
        "    userfilepath = input('please enter folder name to be stored under')\n",
        "    exists = os.path.exists(userfilepath)\n",
        "  else:\n",
        "    valid = True\n",
        "    print(f'{userfilepath} will be used as images folder')\n",
        "    exists = False\n",
        "if valid == False:\n",
        "  os.makedirs(userfilepath)\n",
        "  print(f'{userfilepath} created')\n",
        "\n",
        "  #download images process\n",
        "\n",
        "from googledriver import download_folder\n",
        "download_folder(url, userfilepath)\n",
        "\n",
        "maxprice = input('please enter max price of clothing')\n",
        "while maxprice.isdigit() == False:\n",
        "  print('Please enter a numerical value')\n",
        "  maxprice = input('please enter max price of clothing')\n",
        "print('price accepted')\n",
        "\n",
        "\n",
        "#test model and return image-class pairs\n",
        "allimages = return_model_run()\n",
        "print(allimages)\n",
        "#sort classes into most popular\n",
        "allimages = find_frequencies(allimages)\n",
        "sorted = mergesort(allimages)\n",
        "sorted_list = []\n",
        "for i in range (0, len(sorted)):\n",
        "  sorted_list.append(sorted[i][0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E78HjuSLkZN",
        "outputId": "259fcb0e-6b38-438c-faae-5dd22c93b29a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "please enter google drive linkhttps://drive.google.com/drive/folders/1EFgLw_qYrTjzmCTf4AoBzjA71UQJK1zD?usp=drive_link\n",
            "link accepted\n",
            "please enter file name to be stored underrecommendations\n",
            "file already exists, use this folder? Y/NY\n",
            "/content/recommendations will be used as images folder\n",
            "please enter max price of clothing40\n",
            "price accepted\n",
            "1/1 [==============================] - 0s 281ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-843f1c7526f8>:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  features = int(features)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 119ms/step\n",
            "['Adios_Jersey', 'Open-Back_Blouse', 'Satin_Joggers']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## RESULTS\n",
        "\n",
        "#uses API and parameters to search for the most popular category from the images\n",
        "#subject to maximum price given\n",
        "def search_ebay(item):\n",
        "  params = {\n",
        "    \"engine\": \"ebay\",\n",
        "    \"_nkw\": f\"{item}\",\n",
        "    \"location\": \"United Kingdom\",\n",
        "    \"ebay_domain\": \"ebay.com\",\n",
        "    \"hl\": \"en\",\n",
        "    \"gl\": \"uk\",\n",
        "    \"api_key\": \"5d4e269b5b82f516868d604bbbfbc27353b4890f26b7403ffb465210d90f8d3e\",\n",
        "    \"tbs\": f\",ppr_min:0,ppr_max:{maxprice}\",\n",
        "    \"num\": \"3\"\n",
        "  }\n",
        "  search = GoogleSearch(params)\n",
        "  results = search.get_dict()\n",
        "  return results\n",
        "\n",
        "#return ebay search results\n",
        "for i in range (0, 3):\n",
        "  item = sorted_list[i].split('_')\n",
        "  item = ' '.join(item)\n",
        "  results = search_ebay(item)\n",
        "#results = pd.DataFrame.from_dict(results)\n",
        "  for i in range (0, 3):\n",
        "    print(results['organic_results'][i]['link'])\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80UjZikOMEad",
        "outputId": "41b677c9-f3e6-4f9f-924c-3a5cc90a60fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EBAY LINKS\n",
            "\n",
            "https://www.ebay.com/itm/395546323498?itmmeta=01J3N3103T9PFTQ8GDNY9WET53&hash=item5c1865ea2a:g:xmgAAOSw~4BmnWKw&itmprp=enc%3AAQAJAAAAwIT%2FZskq%2B7jLS8NAovxUWPwxl6fLTsyeQgwt%2FxGswVdfspjaDq5wiwewW8RAuUBdrLlxXiydIHTIDLP1dHzGKEPeA6ucDv4GCko83Fg4DmF949xntMnU1bRZjN61a780K3OvkD%2B8Atha8SgB1JYJSOySC%2BWuTsvwSO3wd7lEQLLPoMnvfpFpBqmlu7RptajS0MoMx5sUcrIkEMBXtspXJpEhBamsinnA%2B77eJpDU9ZHMMYq0KRzslBBEwrlB0sq%2BiQ%3D%3D%7Ctkp%3ABlBMUPyBhKOdZA\n",
            
            "https://www.ebay.com/itm/166852633651?itmmeta=01J3N3103T4C8H1GQ9QVPEG59K&hash=item26d9312433:g:GyoAAOSwly9mhYpx&itmprp=enc%3AAQAJAAAA4AzumqSv4XnpWJZu1kNEgQr%2FTtbChzngWgJp3cAI7fwB634EgwrlQgn8IEveNNKrK7rT5IvhgL7mgRr6674gT575BfJet8nqidairRPXzkDtk%2FTJOWqWSPeu8qcI17LF4KuHdguwhfOluHDpIsT6p5XODV0XVt0sRlduDWeOlnGtLw%2FNMYvcSNpZBzs%2Btb%2FuaG%2FxP%2B2bjXMxVqSf1UJ461Kr%2BsYV2hMuFkKnf2SIBQAjFqoBxFIPjhl%2FtYKi6If%2Bo%2FRrozKyw8a1VhEU83MmRbNyWDfiQlpTEY%2FPvGV556PZ%7Ctkp%3ABFBM_IGEo51k\n",
            
            "https://www.ebay.com/itm/176484852761?itmmeta=01J3N3103T2FYB8HPBS15QSCBC&hash=item2917512419:g:SiIAAOSwyLpmnsr1&itmprp=enc%3AAQAJAAAA4KuqBjXTqB80KMVKkp%2BLhCkqk9tJjIgMcLqYiDCi9vW7ps9vdLKAHXWOOBTutJaZAyRmVjlg3LOBGjzY9nrE57wlCHP%2FwIQ%2BHDlvm5aJt7cr237G04xZdNYvVULZWyEAoUz3JVpOASzRSeXH5YJdCUr9KOqGk%2FnOrX8RlqdmibKD31tcIDr%2Fz4HsRX2X5sT0HdgWTgd04zVGET6eXnltNcxu4gOBcvHB6EgW92Iqs283jw80PGiP%2F4jQw4Jh1KWfK%2B7Gzy8OwMuqfAxjXCGDfuN1Qx7pZytHtJpLvy3vkAPf%7Ctkp%3ABFBM_oGEo51k\n",
            
            "https://www.ebay.com/itm/266433307202?itmmeta=01J3N30XWYT4ANQ7W621MT8AJJ&hash=item3e08a9a242:g:SToAAOSwsFplFp7i&itmprp=enc%3AAQAJAAAAwN%2FhTJJYLDOGAT6VA%2BsTiWm9pvUkbZnblysUJNALBMNtH5RF4yNWkqA0DXzIhXyeuANYp0341ETslrm2MEDYo6SsYA8KNU68GXQhWiJBOAq1a9vQpQvHXLZQzsiSrdDoharroq7Y9zvv2rdW%2B9pjk5%2BchMATo59dWmVSpKV4y7coM7f%2BLZxSvQxaMYEZ4xcW9aW573qEYmPSI8GqQuYJmjP74JcfmMz1Htg%2F4i6XF7bknXvhIWSQt5Q2fALm99Ygpw%3D%3D%7Ctkp%3ABlBMUMjeg6OdZA\n",
            
            "https://www.ebay.com/itm/186591033906?itmmeta=01J3N30XWYJ910FWT4XT71JV15&hash=item2b71b13a32:g:likAAOSwGR5mojIa&itmprp=enc%3AAQAJAAAA4A9IsDO2WtKLSKmLuTes7fUI%2FxPbGJC45kcPkU9QdMU8MbUElotg6tMM5GEBwlkrG3lIbnf%2B%2BjiY%2BBCzRYlgsfW0V%2F3Yk8yKsePoy9JN5YZlNyOVOsNXqcdKvBKsfzBMlHd5axZC0AYtaRX25UKKQ0hpswqzQIp%2FGEqGUx9ZeW06K%2F8t3eEMG9yYXq3EQengX77nIPmKuHq%2Fv6hNkx07xtx%2FWvzI%2BMPPOPLA21zbPogRS3vBH1wG8kUizBGNF77L8es%2FDmrH22HZDq%2Fgixk%2FGaoChWQQMOKNUlG9pZDYe0Lm%7Ctkp%3ABFBMyN6Do51k\n",
            
            "https://www.ebay.com/itm/285964212833?itmmeta=01J3N30XWY321YMC3FYK5M7KTM&hash=item4294cb9a61:g:1aAAAOSwEOtmFY3V&itmprp=enc%3AAQAJAAAA4HZYHdOytHPoPaCvXOl8G5sjJL9ibw3mFcTHiRrecejOO8O8TY5el%2FYaicdgXFbFIV6Syz7kyWhR%2Fl10b0Swqpqbho8s4wqYpRPeF2QB7BTZ2Ub8AUvU3ST%2FvxEf7vSP75kEucvNFtNwY3a5vd6bCaadzyMumwi60asIE88th7pQCN5N0SI0v4FW0VYTvJYUcOtKE4rrzH0evtegx9q1wvvJnUkT09mrP8uw%2BmGLO1wbZw5nawdD34OB%2BbFFwiq3zEOrvbnNvFgRSbHgfBQv5E2Hk81%2BLLIZA15f5f7LdPVt%7Ctkp%3ABFBMyN6Do51k\n",
            
            "https://www.ebay.com/itm/155026358971?itmmeta=01J3N312GH36HVAGJ6SZVNP89K&hash=item24184a82bb:g:RTUAAOSwd0hinhFT&itmprp=enc%3AAQAJAAAA4LWrYdO21hHxXfqNVixS1ox9PxIoUm%2FMZV9BfsrFJAwy6ppsNt1pNeK6Kuzc3RlT7ZotWtF%2BkCcW4R%2BFJyCak%2FuZSbMX7SPO%2Fz26L7%2Brclfms5ZK6wJUpvHD%2BaSAjTEvpx2%2FPHpRPXYf%2Fs485jS8N1rSNaNyOvMgXJPbt2HAxKHOxmIyGlN0oAEDfihd%2FjRTt%2FZQSQrqE2xcRgl2v2dbVODlZzTwBDWcks5SKeTH%2FRV8sa2NimX0BBxvRxuYMvgjfaLZ5ezxmlEf%2FtpMHvP8oQVbVQNz8HqjvNYzhbvjZd0r%7Ctkp%3ABFBMsKiEo51k\n",
            
            "https://www.ebay.com/itm/276565007824?itmmeta=01J3N312GHWETTM965F3DX7T9F&hash=item40648f1dd0:g:jcwAAOSwro9kb2zv&itmprp=enc%3AAQAJAAAA4EvhAjl7nwluNM6EDI8gP3DywpW8Bo7a8tf7qjV%2FCxtliDnQ2O1eTZ2hCfYjbWswql07YT%2Bwl2%2F8M%2BAskOtO3RL9tDhHf1dfWDOEq3jmeZbR9aBsX7FHHTIXyTyJIvtYG9NafY11QzOiq%2FHvlKfgdawR9XX4zmENZIXDuNkXz0ndjuexVIzOSLMyU3z0FTy0sV8hsIbsEc1zLY%2FkCG1IxTOx%2Fy1xdh1Id3KZFNNPcBA5lBObEj0SKnAhg8gegXGt4zhnY3gEddATCc6EuvWCBb5YZyji4%2B%2F3wfDC3mzgh4nU%7Ctkp%3ABFBMsKiEo51k\n",
            
            "https://www.ebay.com/itm/314886809122?itmmeta=01J3N312GHPWSYYM1XFG3JA04X&hash=item4950b76622:g:bhAAAOSw9qplKbJe&itmprp=enc%3AAQAJAAAA4P9rjTQehR4aRgpqpYnrEotS4PKnOmBQW%2FXLU0Odzn9v3sKfKWQerzA7j9%2BNQTx5Vsa3uMZdqPQtj17jah60khtkYrqcP1pYu%2BT7hevWvhwmpFLKI%2B0t6W%2FAIPqiyw%2BwnjkigLISwjXscc05O8eBMs1VGISAmjZ8clkowfHnLz66E%2BdyQez9vsjl59aT%2FIdYrAeacaDMBcamxZQWknjsXOcRHZesZKR3YuD1N37b1mj3vosbreMnjITqme16Q433MPxUhGOFFHBCembTYYwU05HVuNxxwkKFsk08irB61DsF%7Ctkp%3ABFBMsKiEo51k\n"
            
          ]
        }
      ]
    }
  ]
}
